{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install and Set Up Kaggle and API Key\n",
    "\n",
    "Follow these steps to install and configure the Kaggle API on your system:\n",
    "\n",
    "1. **Create a Kaggle Account**\n",
    "   - Visit [Kaggle](https://www.kaggle.com) and sign up for an account.\n",
    "\n",
    "2. **Obtain Kaggle API Key**\n",
    "   - Go to your Kaggle account settings.\n",
    "   - Find the \"API\" section and click on \"Create New API Token\".\n",
    "   - This will download a `kaggle.json` file containing your API key.\n",
    "\n",
    "3. **Install Kaggle Package**\n",
    "   - Use Conda to install the Kaggle package by running:\n",
    "     ```bash\n",
    "     conda install kaggle\n",
    "     ```\n",
    "\n",
    "4. **Configure API Key**\n",
    "   - Copy the `kaggle.json` file to your user directory under the `.kaggle` folder. On most systems, you can use the following command:\n",
    "     ```bash\n",
    "     mkdir -p ~/.kaggle\n",
    "     cp path_to_downloaded_kaggle.json ~/.kaggle/kaggle.json\n",
    "     chmod 600 ~/.kaggle/kaggle.json\n",
    "     ```\n",
    "   - Ensure the `.kaggle` directory and the `kaggle.json` file have the proper permissions by setting:\n",
    "     ```bash\n",
    "     chmod 600 ~/.kaggle/kaggle.json\n",
    "     ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import kaggle\n",
    "# Pre processing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, OrdinalEncoder\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Scoring \n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# models \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#potting\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/rodsaldanha/arketing-campaign\n"
     ]
    }
   ],
   "source": [
    "# Get the data using an API call\n",
    "kaggle.api.dataset_download_files('rodsaldanha/arketing-campaign', path='resources', unzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "data = pd.read_csv(\"./resources/marketing_campaign.csv\",delimiter=';')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA (Exploratory Data Analysis)\n",
    "We will revisit this. For now We want the rough draft of the model\n",
    "#\n",
    "During EDA\n",
    "\n",
    "Visualize the data using plots and graphs to understand distributions and relationships between variables.\n",
    "Calculate summary statistics to get a sense of the central tendencies and variability.\n",
    "Identify any correlations between variables that might influence model choices.\n",
    "Detect and treat missing values or outliers that could skew the results of your analysis.\n",
    "Explore the data's structure to inform feature selection and engineering, which are key to building effective machine learning models.\n",
    "\n",
    "# read any and all documentation you can find on your dataset to understand it better\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Year_Birth</th>\n",
       "      <th>Education</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Income</th>\n",
       "      <th>Kidhome</th>\n",
       "      <th>Teenhome</th>\n",
       "      <th>Dt_Customer</th>\n",
       "      <th>Recency</th>\n",
       "      <th>MntWines</th>\n",
       "      <th>...</th>\n",
       "      <th>NumWebVisitsMonth</th>\n",
       "      <th>AcceptedCmp3</th>\n",
       "      <th>AcceptedCmp4</th>\n",
       "      <th>AcceptedCmp5</th>\n",
       "      <th>AcceptedCmp1</th>\n",
       "      <th>AcceptedCmp2</th>\n",
       "      <th>Complain</th>\n",
       "      <th>Z_CostContact</th>\n",
       "      <th>Z_Revenue</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5524</td>\n",
       "      <td>1957</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Single</td>\n",
       "      <td>58138.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-09-04</td>\n",
       "      <td>58</td>\n",
       "      <td>635</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2174</td>\n",
       "      <td>1954</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Single</td>\n",
       "      <td>46344.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-03-08</td>\n",
       "      <td>38</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4141</td>\n",
       "      <td>1965</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Together</td>\n",
       "      <td>71613.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-08-21</td>\n",
       "      <td>26</td>\n",
       "      <td>426</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6182</td>\n",
       "      <td>1984</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Together</td>\n",
       "      <td>26646.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-02-10</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5324</td>\n",
       "      <td>1981</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Married</td>\n",
       "      <td>58293.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-01-19</td>\n",
       "      <td>94</td>\n",
       "      <td>173</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID  Year_Birth   Education Marital_Status   Income  Kidhome  Teenhome  \\\n",
       "0  5524        1957  Graduation         Single  58138.0        0         0   \n",
       "1  2174        1954  Graduation         Single  46344.0        1         1   \n",
       "2  4141        1965  Graduation       Together  71613.0        0         0   \n",
       "3  6182        1984  Graduation       Together  26646.0        1         0   \n",
       "4  5324        1981         PhD        Married  58293.0        1         0   \n",
       "\n",
       "  Dt_Customer  Recency  MntWines  ...  NumWebVisitsMonth  AcceptedCmp3  \\\n",
       "0  2012-09-04       58       635  ...                  7             0   \n",
       "1  2014-03-08       38        11  ...                  5             0   \n",
       "2  2013-08-21       26       426  ...                  4             0   \n",
       "3  2014-02-10       26        11  ...                  6             0   \n",
       "4  2014-01-19       94       173  ...                  5             0   \n",
       "\n",
       "   AcceptedCmp4  AcceptedCmp5  AcceptedCmp1  AcceptedCmp2  Complain  \\\n",
       "0             0             0             0             0         0   \n",
       "1             0             0             0             0         0   \n",
       "2             0             0             0             0         0   \n",
       "3             0             0             0             0         0   \n",
       "4             0             0             0             0         0   \n",
       "\n",
       "   Z_CostContact  Z_Revenue  Response  \n",
       "0              3         11         1  \n",
       "1              3         11         0  \n",
       "2              3         11         0  \n",
       "3              3         11         0  \n",
       "4              3         11         0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2240, 29)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with NA valuses \n",
      " Income    24\n",
      "dtype: int64\n",
      "Columns that are not numeric :\n",
      " ['Education', 'Marital_Status', 'Dt_Customer']\n"
     ]
    }
   ],
   "source": [
    "display (data.head())\n",
    "# what does our data look like? At this point also use any documentation on the data set to find out what each value means and how it might be used is solving the business problem\n",
    "display (data.shape)\n",
    "print (f'Columns with NA valuses \\n {data.isna().sum()[lambda x: x > 0]}')\n",
    "# Make desision about null values. Can we fill them of should we drop rows with null values?\n",
    "non_numeric= (data.dtypes[(data.dtypes != 'int64') & (data.dtypes != 'float64')]).index.tolist()\n",
    "# display (data.dtypes)\n",
    "print (f'Columns that are not numeric :\\n {non_numeric}')\n",
    "# Explore non numberic type to see how we can use them in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Training Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Kidhome</th>\n",
       "      <th>Teenhome</th>\n",
       "      <th>Recency</th>\n",
       "      <th>MntWines</th>\n",
       "      <th>MntFruits</th>\n",
       "      <th>MntMeatProducts</th>\n",
       "      <th>MntFishProducts</th>\n",
       "      <th>MntSweetProducts</th>\n",
       "      <th>MntGoldProds</th>\n",
       "      <th>...</th>\n",
       "      <th>AcceptedCmp5</th>\n",
       "      <th>AcceptedCmp1</th>\n",
       "      <th>AcceptedCmp2</th>\n",
       "      <th>Complain</th>\n",
       "      <th>Z_CostContact</th>\n",
       "      <th>Z_Revenue</th>\n",
       "      <th>Months_Customer</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Education</th>\n",
       "      <th>Generation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16813.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64191.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>420</td>\n",
       "      <td>15</td>\n",
       "      <td>186</td>\n",
       "      <td>151</td>\n",
       "      <td>38</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71969.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29187.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4428.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>321</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Income  Kidhome  Teenhome  Recency  MntWines  MntFruits  MntMeatProducts  \\\n",
       "0  16813.0        0         0       49         4          8               11   \n",
       "1  64191.0        0         1       30       420         15              186   \n",
       "2  71969.0        0         1       59      1000          0               76   \n",
       "3  29187.0        1         0       43        26          0                6   \n",
       "4   4428.0        0         1        0        16          4               12   \n",
       "\n",
       "   MntFishProducts  MntSweetProducts  MntGoldProds  ...  AcceptedCmp5  \\\n",
       "0               12                 2            13  ...             0   \n",
       "1              151                38            15  ...             0   \n",
       "2                0                 0            10  ...             0   \n",
       "3                0                 0             2  ...             0   \n",
       "4                2                 4           321  ...             0   \n",
       "\n",
       "   AcceptedCmp1  AcceptedCmp2  Complain  Z_CostContact  Z_Revenue  \\\n",
       "0             0             0         0              3         11   \n",
       "1             0             0         0              3         11   \n",
       "2             0             0         0              3         11   \n",
       "3             0             0         0              3         11   \n",
       "4             0             0         0              3         11   \n",
       "\n",
       "   Months_Customer  Marital_Status  Education  Generation  \n",
       "0               11             2.0        2.0         2.0  \n",
       "1               17             2.0        3.0         2.0  \n",
       "2               20             0.0        4.0         3.0  \n",
       "3               13             0.0        4.0         3.0  \n",
       "4                8             0.0        2.0         3.0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Test Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Kidhome</th>\n",
       "      <th>Teenhome</th>\n",
       "      <th>Recency</th>\n",
       "      <th>MntWines</th>\n",
       "      <th>MntFruits</th>\n",
       "      <th>MntMeatProducts</th>\n",
       "      <th>MntFishProducts</th>\n",
       "      <th>MntSweetProducts</th>\n",
       "      <th>MntGoldProds</th>\n",
       "      <th>...</th>\n",
       "      <th>AcceptedCmp5</th>\n",
       "      <th>AcceptedCmp1</th>\n",
       "      <th>AcceptedCmp2</th>\n",
       "      <th>Complain</th>\n",
       "      <th>Z_CostContact</th>\n",
       "      <th>Z_Revenue</th>\n",
       "      <th>Months_Customer</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Education</th>\n",
       "      <th>Generation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40464.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>424</td>\n",
       "      <td>17</td>\n",
       "      <td>118</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47916.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>505</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14188.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76653.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>736</td>\n",
       "      <td>63</td>\n",
       "      <td>946</td>\n",
       "      <td>219</td>\n",
       "      <td>189</td>\n",
       "      <td>126</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65196.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>743</td>\n",
       "      <td>19</td>\n",
       "      <td>181</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Income  Kidhome  Teenhome  Recency  MntWines  MntFruits  MntMeatProducts  \\\n",
       "0  40464.0        0         1       78       424         17              118   \n",
       "1  47916.0        0         1       72       505          0               26   \n",
       "2  14188.0        0         0       40         2          7               11   \n",
       "3  76653.0        0         0       91       736         63              946   \n",
       "4  65196.0        0         2       34       743         19              181   \n",
       "\n",
       "   MntFishProducts  MntSweetProducts  MntGoldProds  ...  AcceptedCmp5  \\\n",
       "0                7                23            41  ...             0   \n",
       "1                0                 0            75  ...             0   \n",
       "2               16                12            27  ...             0   \n",
       "3              219               189           126  ...             1   \n",
       "4               12                 0           200  ...             0   \n",
       "\n",
       "   AcceptedCmp1  AcceptedCmp2  Complain  Z_CostContact  Z_Revenue  \\\n",
       "0             0             0         0              3         11   \n",
       "1             0             0         0              3         11   \n",
       "2             0             0         0              3         11   \n",
       "3             1             0         0              3         11   \n",
       "4             0             0         0              3         11   \n",
       "\n",
       "   Months_Customer  Marital_Status  Education  Generation  \n",
       "0               17             2.0        2.0         2.0  \n",
       "1               19             4.0        2.0         2.0  \n",
       "2               16             0.0        0.0         3.0  \n",
       "3               10             1.0        2.0         3.0  \n",
       "4               11             1.0        2.0         2.0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Split the data into training and test sets with an 80/20 split\n",
    "X = data.drop('Response', axis=1)\n",
    "y = data[\"Response\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# Define the generational labels and ranges\n",
    "def assign_generation(year):\n",
    "    if year <= 1927:\n",
    "        return 'Greatest Generation'\n",
    "    elif 1928 <= year <= 1945:\n",
    "        return 'Silent Generation'\n",
    "    elif 1946 <= year <= 1964:\n",
    "        return 'Baby Boomers'\n",
    "    elif 1965 <= year <= 1980:\n",
    "        return 'Generation X'\n",
    "    elif 1981 <= year <= 1996:\n",
    "        return 'Millennials (Gen Y)'\n",
    "    elif 1997 <= year <= 2012:\n",
    "        return 'Generation Z (Gen Z)'\n",
    "    else:\n",
    "        return 'Generation Alpha'\n",
    "\n",
    "# Apply the function to create a new column 'Generation'\n",
    "X_train['Generation'] = X_train['Year_Birth'].apply(assign_generation)\n",
    "X_test['Generation'] = X_test['Year_Birth'].apply(assign_generation)\n",
    "\n",
    "# Calculate Months as Customer\n",
    "X_train['Dt_Customer'] = pd.to_datetime(X_train['Dt_Customer'])\n",
    "X_test['Dt_Customer'] = pd.to_datetime(X_test['Dt_Customer'])\n",
    "current_date = datetime(2014, 6, 29)\n",
    "X_train['Months_Customer'] = ((current_date.year - X_train['Dt_Customer'].dt.year) * 12 +\n",
    "                              (current_date.month - X_train['Dt_Customer'].dt.month))\n",
    "X_test['Months_Customer'] = ((current_date.year - X_test['Dt_Customer'].dt.year) * 12 +\n",
    "                             (current_date.month - X_test['Dt_Customer'].dt.month))\n",
    "X_train = X_train.drop('Dt_Customer', axis=1)\n",
    "X_test = X_test.drop('Dt_Customer', axis=1)\n",
    "\n",
    "# Drop unnecessary columns and handle NA\n",
    "X_train = X_train.drop(columns=[\"ID\", \"Year_Birth\"]).dropna()\n",
    "X_test = X_test.drop(columns=[\"ID\", \"Year_Birth\"]).dropna()\n",
    "\n",
    "# Create encoders for the categorical variables\n",
    "Mar_ord_enc = OrdinalEncoder(categories=[['Married', 'Together', 'Single', 'Divorced', 'Widow', \"YOLO\", \"Absurd\", \"Alone\"]])\n",
    "edu_ord_enc = OrdinalEncoder(categories=[['Basic', '2n Cycle', 'Graduation', 'Master', 'PhD']])\n",
    "Age_ord_enc = OrdinalEncoder(categories=[['Greatest Generation', 'Silent Generation', 'Baby Boomers', 'Generation X', 'Millennials (Gen Y)', 'Generation Z (Gen Z)', 'Generation Alpha']])\n",
    "\n",
    "# Train the encoders on the training data\n",
    "Mar_ord_enc.fit(X_train['Marital_Status'].values.reshape(-1, 1))\n",
    "edu_ord_enc.fit(X_train['Education'].values.reshape(-1, 1))\n",
    "Age_ord_enc.fit(X_train['Generation'].values.reshape(-1, 1))\n",
    "\n",
    "# Preprocessing function\n",
    "def X_preprocess(X_data):\n",
    "    # Ensure the data is in the correct format\n",
    "    X_data = X_data.copy()\n",
    "    \n",
    "    # Transform each column into numpy arrays\n",
    "    marital_status_encoded = Mar_ord_enc.transform(X_data['Marital_Status'].values.reshape(-1, 1))\n",
    "    education_encoded = edu_ord_enc.transform(X_data['Education'].values.reshape(-1, 1))\n",
    "    generation_encoded = Age_ord_enc.transform(X_data['Generation'].values.reshape(-1, 1))\n",
    "    \n",
    "    # Reorganize the numpy arrays into DataFrames\n",
    "    marital_status_encoded_df = pd.DataFrame(marital_status_encoded, columns=Mar_ord_enc.get_feature_names_out(['Marital_Status']))\n",
    "    education_encoded_df = pd.DataFrame(education_encoded, columns=edu_ord_enc.get_feature_names_out(['Education']))\n",
    "    generation_encoded_df = pd.DataFrame(generation_encoded, columns=Age_ord_enc.get_feature_names_out(['Generation']))\n",
    "    \n",
    "    # Drop the original categorical columns from the original DataFrame\n",
    "    X_data = X_data.drop(['Education', 'Marital_Status', 'Generation'], axis=1)\n",
    "    \n",
    "    # Combine the encoded columns with the remaining DataFrame\n",
    "    out_df = pd.concat([X_data.reset_index(drop=True), marital_status_encoded_df.reset_index(drop=True), \n",
    "                        education_encoded_df.reset_index(drop=True), generation_encoded_df.reset_index(drop=True)], axis=1)\n",
    "    \n",
    "    # Return the DataFrame\n",
    "    return out_df\n",
    "\n",
    "# Preprocess the training and test data\n",
    "X_train_proc = X_preprocess(X_train)\n",
    "X_test_proc = X_preprocess(X_test)\n",
    "\n",
    "# Check if preprocessing was successful\n",
    "print(\"Processed Training Data:\")\n",
    "display(X_train_proc.head())\n",
    "print(\"Processed Test Data:\")\n",
    "display(X_test_proc.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA Transformed Training Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-35152.186917</td>\n",
       "      <td>31.597319</td>\n",
       "      <td>32.848204</td>\n",
       "      <td>1.789405</td>\n",
       "      <td>-7.501221</td>\n",
       "      <td>-2.829838</td>\n",
       "      <td>0.427663</td>\n",
       "      <td>-4.072570</td>\n",
       "      <td>-0.160827</td>\n",
       "      <td>0.990543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12227.965632</td>\n",
       "      <td>-21.849950</td>\n",
       "      <td>-43.830221</td>\n",
       "      <td>-41.415119</td>\n",
       "      <td>-77.324019</td>\n",
       "      <td>-71.377419</td>\n",
       "      <td>6.765761</td>\n",
       "      <td>20.530422</td>\n",
       "      <td>6.455263</td>\n",
       "      <td>-3.845308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20009.083875</td>\n",
       "      <td>-443.535123</td>\n",
       "      <td>-395.026110</td>\n",
       "      <td>80.324073</td>\n",
       "      <td>-14.255150</td>\n",
       "      <td>-5.520105</td>\n",
       "      <td>-10.089668</td>\n",
       "      <td>-6.703858</td>\n",
       "      <td>7.934384</td>\n",
       "      <td>1.842306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-22778.558987</td>\n",
       "      <td>120.312846</td>\n",
       "      <td>-8.173473</td>\n",
       "      <td>23.816314</td>\n",
       "      <td>-7.760422</td>\n",
       "      <td>-2.036845</td>\n",
       "      <td>5.244189</td>\n",
       "      <td>0.392524</td>\n",
       "      <td>2.621920</td>\n",
       "      <td>1.779452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-47536.427489</td>\n",
       "      <td>-101.570106</td>\n",
       "      <td>62.688477</td>\n",
       "      <td>-176.968679</td>\n",
       "      <td>243.027108</td>\n",
       "      <td>-1.224416</td>\n",
       "      <td>39.789909</td>\n",
       "      <td>34.591340</td>\n",
       "      <td>-8.969569</td>\n",
       "      <td>-8.244355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0           1           2           3           4          5  \\\n",
       "0 -35152.186917   31.597319   32.848204    1.789405   -7.501221  -2.829838   \n",
       "1  12227.965632  -21.849950  -43.830221  -41.415119  -77.324019 -71.377419   \n",
       "2  20009.083875 -443.535123 -395.026110   80.324073  -14.255150  -5.520105   \n",
       "3 -22778.558987  120.312846   -8.173473   23.816314   -7.760422  -2.036845   \n",
       "4 -47536.427489 -101.570106   62.688477 -176.968679  243.027108  -1.224416   \n",
       "\n",
       "           6          7         8         9  \n",
       "0   0.427663  -4.072570 -0.160827  0.990543  \n",
       "1   6.765761  20.530422  6.455263 -3.845308  \n",
       "2 -10.089668  -6.703858  7.934384  1.842306  \n",
       "3   5.244189   0.392524  2.621920  1.779452  \n",
       "4  39.789909  34.591340 -8.969569 -8.244355  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA Transformed Test Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-11498.543209</td>\n",
       "      <td>-197.129972</td>\n",
       "      <td>-72.099263</td>\n",
       "      <td>18.211767</td>\n",
       "      <td>8.242871</td>\n",
       "      <td>16.639759</td>\n",
       "      <td>-27.646249</td>\n",
       "      <td>-3.707407</td>\n",
       "      <td>5.346095</td>\n",
       "      <td>-5.128432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4046.721436</td>\n",
       "      <td>-175.297660</td>\n",
       "      <td>-204.750293</td>\n",
       "      <td>7.911844</td>\n",
       "      <td>43.281052</td>\n",
       "      <td>-1.192585</td>\n",
       "      <td>-24.563606</td>\n",
       "      <td>-2.758675</td>\n",
       "      <td>6.544814</td>\n",
       "      <td>-1.571801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-37777.080684</td>\n",
       "      <td>9.742819</td>\n",
       "      <td>40.474342</td>\n",
       "      <td>-13.064699</td>\n",
       "      <td>-1.202207</td>\n",
       "      <td>-0.139200</td>\n",
       "      <td>7.514445</td>\n",
       "      <td>6.226917</td>\n",
       "      <td>4.299542</td>\n",
       "      <td>1.161635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24695.770357</td>\n",
       "      <td>-500.535235</td>\n",
       "      <td>533.811060</td>\n",
       "      <td>-84.078729</td>\n",
       "      <td>-40.540799</td>\n",
       "      <td>-3.833161</td>\n",
       "      <td>-59.921675</td>\n",
       "      <td>79.003943</td>\n",
       "      <td>-4.684441</td>\n",
       "      <td>1.088351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13235.179062</td>\n",
       "      <td>-312.482269</td>\n",
       "      <td>-181.238870</td>\n",
       "      <td>-41.665355</td>\n",
       "      <td>139.592048</td>\n",
       "      <td>-7.725662</td>\n",
       "      <td>12.404966</td>\n",
       "      <td>1.328137</td>\n",
       "      <td>-3.806295</td>\n",
       "      <td>-1.398428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0           1           2          3           4          5  \\\n",
       "0 -11498.543209 -197.129972  -72.099263  18.211767    8.242871  16.639759   \n",
       "1  -4046.721436 -175.297660 -204.750293   7.911844   43.281052  -1.192585   \n",
       "2 -37777.080684    9.742819   40.474342 -13.064699   -1.202207  -0.139200   \n",
       "3  24695.770357 -500.535235  533.811060 -84.078729  -40.540799  -3.833161   \n",
       "4  13235.179062 -312.482269 -181.238870 -41.665355  139.592048  -7.725662   \n",
       "\n",
       "           6          7         8         9  \n",
       "0 -27.646249  -3.707407  5.346095 -5.128432  \n",
       "1 -24.563606  -2.758675  6.544814 -1.571801  \n",
       "2   7.514445   6.226917  4.299542  1.161635  \n",
       "3 -59.921675  79.003943 -4.684441  1.088351  \n",
       "4  12.404966   1.328137 -3.806295 -1.398428  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize PCA with 10 components\n",
    "pca_model = PCA(n_components=10)\n",
    "\n",
    "# Fit PCA on the training data\n",
    "pca_model.fit(X_train_proc)\n",
    "\n",
    "# Transform the training and testing data\n",
    "X_train_pca = pd.DataFrame(pca_model.transform(X_train_proc))\n",
    "X_test_pca = pd.DataFrame(pca_model.transform(X_test_proc))\n",
    "\n",
    "# Display the first few rows of the transformed data\n",
    "print(\"PCA Transformed Training Data:\")\n",
    "display(X_train_pca.head())\n",
    "print(\"PCA Transformed Test Data:\")\n",
    "display(X_test_pca.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response\n",
      "1    1906\n",
      "0    1906\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Applying RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "# Check the new class distribution\n",
    "print(y_resampled.value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response\n",
      "0    334\n",
      "1    334\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Applying RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_resampled, y_resampled = rus.fit_resample(X, y)\n",
    "\n",
    "# Check the new class distribution\n",
    "print(y_resampled.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Graduation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/t7/hxd3pgr11qjblzs42br5s1_40000gn/T/ipykernel_57223/885514247.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Applying SMOTE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msmote\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mX_resampled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_resampled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmote\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Check the new class distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_resampled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dev/lib/python3.10/site-packages/imblearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0my_resampled\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlike\u001b[0m \u001b[0mof\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_samples_new\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mX_resampled\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \"\"\"\n\u001b[1;32m    207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/dev/lib/python3.10/site-packages/imblearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mX_resampled\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \"\"\"\n\u001b[1;32m    104\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0marrays_transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mArraysTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         self.sampling_strategy_ = check_sampling_strategy(\n\u001b[1;32m    109\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampling_strategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampling_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dev/lib/python3.10/site-packages/imblearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, accept_sparse)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maccept_sparse\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0maccept_sparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_target_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindicate_one_vs_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinarize_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dev/lib/python3.10/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"estimator\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheck_y_params\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m                     \u001b[0mcheck_y_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdefault_check_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dev/lib/python3.10/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1143\u001b[0m         raise ValueError(\n\u001b[1;32m   1144\u001b[0m             \u001b[0;34mf\"{estimator_name} requires y to be passed, but the target y is None\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m         )\n\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m   1148\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dev/lib/python3.10/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    914\u001b[0m                         )\n\u001b[1;32m    915\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m                 raise ValueError(\n\u001b[1;32m    920\u001b[0m                     \u001b[0;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m                 ) from complex_warning\n",
      "\u001b[0;32m~/anaconda3/envs/dev/lib/python3.10/site-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;31m# Use NumPy API to support order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;31m# container that is consistent with the input's namespace.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dev/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1996\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1998\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1999\u001b[0m         if (\n\u001b[1;32m   2000\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2001\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Graduation'"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Applying SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Check the new class distribution\n",
    "print(y_resampled.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Split the original data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# Train a RandomForestClassifier with class weights\n",
    "clf = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "# Applying SMOTEENN (combination of SMOTE and Edited Nearest Neighbors)\n",
    "smote_enn = SMOTEENN(random_state=42)\n",
    "X_resampled, y_resampled = smote_enn.fit_resample(X, y)\n",
    "\n",
    "# Split the resampled data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.20, random_state=42)\n",
    "\n",
    "# Train and evaluate the model\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the X data by using StandardScaler()\n",
    "scaler_ss = StandardScaler().fit(X_train)\n",
    "X_train_ss_scaled = scaler_ss.transform(X_train)\n",
    "display (X_train_ss_scaled)\n",
    "\n",
    "# Transform the test dataset based on the fit from the training dataset\n",
    "X_test_ss_scaled = scaler_ss.transform(X_test)\n",
    "display (X_test_ss_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets look at min max scaler\n",
    "scaler_mm = MinMaxScaler().fit(X_train)\n",
    "X_train_mm_scaled = scaler_mm.transform(X_train)\n",
    "display (X_train_mm_scaled)\n",
    "#\n",
    "X_test_mm_scaled = scaler_mm.transform(X_test)\n",
    "display (X_test_mm_scaled)\n",
    "\n",
    "X_test_mm_scaled = scaler_mm.transform(X_test)\n",
    "display (X_test_mm_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Logistic model to find out what scaler works best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a `LogisticRegression` function and assign it \n",
    "# to a variable named `logistic_regression_model`.\n",
    "logistic_regression_model_ss = LogisticRegression()\n",
    "logistic_regression_model_ss.fit(X_train_ss_scaled, y_train)\n",
    "#\n",
    "logistic_regression_model_mm = LogisticRegression()\n",
    "logistic_regression_model_mm.fit(X_train_mm_scaled, y_train)\n",
    "# Score the Logistic model\n",
    "\n",
    "print(f\"Standard Scaler\\nTraining Data Score: {logistic_regression_model_ss.score(X_train_ss_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {logistic_regression_model_ss.score(X_test_ss_scaled, y_test)}\")\n",
    "print(f\"Min Max Scaler\\nTraining Data Score: {logistic_regression_model_mm.score(X_train_mm_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {logistic_regression_model_mm.score(X_test_mm_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test models\n",
    "    -RANDOM FOREST MODEL\n",
    "    -GradientBoostingClassifier\n",
    "    -KNeighborsClassifier\n",
    "    -SVM (Support Vector Machine)\n",
    "    -LogisticRegression\n",
    "    -Decision Tree Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **RANDOM FOREST MODEL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the model\n",
    "random_forest_model = RandomForestClassifier(random_state=42)\n",
    "random_forest_model.fit(X_train, y_train)\n",
    "# Predict on test set\n",
    "y_pred = random_forest_model.predict(X_test)\n",
    "# Calculate precision, recall, F1 score\n",
    "# Cross-validation scores\n",
    "cv_scores = cross_val_score(random_forest_model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "display (random_forest_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and train the model\n",
    "random_forest_model = RandomForestClassifier(random_state=42)\n",
    "random_forest_model.fit(X_train_ss_scaled, y_train)\n",
    "# Predict on test set\n",
    "y_pred = random_forest_model.predict(X_test_ss_scaled)\n",
    "# Calculate precision, recall, F1 score\n",
    "# Cross-validation scores\n",
    "cv_scores = cross_val_score(random_forest_model, X_train_ss_scaled, y_train, cv=5, scoring='accuracy')\n",
    "display (random_forest_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the model\n",
    "random_forest_model = RandomForestClassifier(random_state=42)\n",
    "random_forest_model.fit(X_train_ss_scaled, y_train)\n",
    "# Predict on test set\n",
    "y_pred = random_forest_model.predict(X_test_ss_scaled)\n",
    "# Calculate precision, recall, F1 score\n",
    "# Cross-validation scores\n",
    "cv_scores = cross_val_score(random_forest_model, X_train_ss_scaled, y_train, cv=5, scoring='accuracy')\n",
    "display (random_forest_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradientBoostingClassifier MODELING\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and train the model\n",
    "gbm_model = GradientBoostingClassifier(random_state=42)\n",
    "gbm_model.fit(X_train_ss_scaled, y_train)\n",
    "# Predict on test set\n",
    "y_pred = gbm_model.predict(X_test_ss_scaled)\n",
    "cv_scores = cross_val_score(gbm_model, X_train_ss_scaled, y_train, cv=5, scoring='accuracy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Create and train the model\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(X_train_ss_scaled, y_train)\n",
    "# Predict on test set\n",
    "y_pred = knn_model.predict(X_test_ss_scaled)\n",
    "cv_scores = cross_val_score(knn_model, X_train_ss_scaled, y_train, cv=5, scoring='accuracy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC (Support Vector Machine) Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Create and train the model\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train_ss_scaled, y_train)\n",
    "# Predict on test set\n",
    "y_pred = svm_model.predict(X_test_ss_scaled)\n",
    "# Cross-validation scores\n",
    "cv_scores = cross_val_score(svm_model, X_train_ss_scaled, y_train, cv=5, scoring='accuracy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogisticRegression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and train the model\n",
    "logistic_regression_model = LogisticRegression()\n",
    "logistic_regression_model.fit(X_train_ss_scaled, y_train)\n",
    "# Predict on test set\n",
    "y_pred = logistic_regression_model.predict(X_test_ss_scaled)\n",
    "# Cross-validation scores\n",
    "cv_scores = cross_val_score(logistic_regression_model, X_train_ss_scaled, y_train, cv=5, scoring='accuracy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the model\n",
    "decision_tree_model = DecisionTreeClassifier(random_state=42)\n",
    "decision_tree_model.fit(X_train_ss_scaled, y_train)\n",
    "# Predict on test set\n",
    "y_pred = decision_tree_model.predict(X_test_ss_scaled)\n",
    "# Cross-validation scores\n",
    "cv_scores = cross_val_score(decision_tree_model, X_train_ss_scaled, y_train, cv=5, scoring='accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test models\n",
    "# -RANDOM FOREST MODEL\n",
    "# Score the model\n",
    "print(f\"Random Forest - Training Data Score: {random_forest_model.score(X_train_ss_scaled, y_train)}\")\n",
    "print(f\"Random Forest - Testing Data Score: {random_forest_model.score(X_test_ss_scaled, y_test)}\")\n",
    "print(f\"Random Forest - Precision: {precision_score(y_test, y_pred)}\")\n",
    "print(f\"Random Forest - Recall: {recall_score(y_test, y_pred)}\")\n",
    "print(f\"Random Forest - F1 Score: {f1_score(y_test, y_pred)}\")\n",
    "print(f\"Random Forest - Cross-Validation Accuracy: {cv_scores.mean()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -GradientBoostingClassifier\n",
    "# Score the model\n",
    "print(f\"Gradient Boosting Machine - Training Data Score: {gbm_model.score(X_train_ss_scaled, y_train)}\")\n",
    "print(f\"Gradient Boosting Machine - Testing Data Score: {gbm_model.score(X_test_ss_scaled, y_test)}\")\n",
    "print(f\"Gradient Boosting Machine - Precision: {precision_score(y_test, y_pred)}\")\n",
    "print(f\"Gradient Boosting Machine - Recall: {recall_score(y_test, y_pred)}\")\n",
    "print(f\"Gradient Boosting Machine - F1 Score: {f1_score(y_test, y_pred)}\")\n",
    "print(f\"Gradient Boosting Machine - Cross-Validation Accuracy: {cv_scores.mean()}\")\n",
    "# -KNeighborsClassifier\n",
    "# Score the model\n",
    "print(f\"K-Nearest Neighbors - Training Data Score: {knn_model.score(X_train_ss_scaled, y_train)}\")\n",
    "print(f\"K-Nearest Neighbors - Testing Data Score: {knn_model.score(X_test_ss_scaled, y_test)}\")\n",
    "print(f\"K-Nearest Neighbors - Precision: {precision_score(y_test, y_pred)}\")\n",
    "print(f\"K-Nearest Neighbors - Recall: {recall_score(y_test, y_pred)}\")\n",
    "print(f\"K-Nearest Neighbors - F1 Score: {f1_score(y_test, y_pred)}\")\n",
    "print(f\"K-Nearest Neighbors - Cross-Validation Accuracy: {cv_scores.mean()}\")\n",
    "# -SVM (Support Vector Machine)\n",
    "# Score the model\n",
    "print(f\"Support Vector Machine - Training Data Score: {svm_model.score(X_train_ss_scaled, y_train)}\")\n",
    "print(f\"Support Vector Machine - Testing Data Score: {svm_model.score(X_test_ss_scaled, y_test)}\")\n",
    "print(f\"Support Vector Machine - Precision: {precision_score(y_test, y_pred)}\")\n",
    "print(f\"Support Vector Machine - Recall: {recall_score(y_test, y_pred)}\")\n",
    "print(f\"Support Vector Machine - F1 Score: {f1_score(y_test, y_pred)}\")\n",
    "print(f\"Support Vector Machine - Cross-Validation Accuracy: {cv_scores.mean()}\")\n",
    "# -LogisticRegression\n",
    "# Score the model\n",
    "print(f\"Logistic Regression - Training Data Score: {logistic_regression_model.score(X_train_ss_scaled, y_train)}\")\n",
    "print(f\"Logistic Regression - Testing Data Score: {logistic_regression_model.score(X_test_ss_scaled, y_test)}\")\n",
    "print(f\"Logistic Regression - Precision: {precision_score(y_test, y_pred)}\")\n",
    "print(f\"Logistic Regression - Recall: {recall_score(y_test, y_pred)}\")\n",
    "print(f\"Logistic Regression - F1 Score: {f1_score(y_test, y_pred)}\")\n",
    "print(f\"Logistic Regression - Cross-Validation Accuracy: {cv_scores.mean()}\")\n",
    "# -Decision Tree Model\n",
    "# Score the model\n",
    "print(f\"Decision Tree - Training Data Score: {decision_tree_model.score(X_train_ss_scaled, y_train)}\")\n",
    "print(f\"Decision Tree - Testing Data Score: {decision_tree_model.score(X_test_ss_scaled, y_test)}\")\n",
    "print(f\"Decision Tree - Precision: {precision_score(y_test, y_pred)}\")\n",
    "print(f\"Decision Tree - Recall: {recall_score(y_test, y_pred)}\")\n",
    "print(f\"Decision Tree - F1 Score: {f1_score(y_test, y_pred)}\")\n",
    "print(f\"Decision Tree - Cross-Validation Accuracy: {cv_scores.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To clearly plot and interpret the results of a model using a RandomForestClassifier to predict customer response based on a list of features, you can follow these steps in your Jupyter Notebook:\n",
    "\n",
    "Fit the Model: Train the RandomForestClassifier on your training data.\n",
    "Make Predictions: Use the model to predict responses on the test set.\n",
    "Evaluate the Model: Calculate key performance metrics like accuracy, precision, recall, and F1-score.\n",
    "Feature Importance: Extract and plot the feature importances to understand which features are most influential in predicting customer responses.\n",
    "Visualize Predictions: Create visualizations to display the predicted responses against actual responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Importance: \n",
    "Extract and plot the feature importances to understand which features are most influential in predicting customer responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Detailed classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "features = X_train.columns\n",
    "importances = random_forest_model.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compare actual and predicted responses\n",
    "# comparison_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "\n",
    "# # Sample some data to plot\n",
    "# sampled_data = comparison_df.sample(50, random_state=42)\n",
    "# sampled_data.plot(kind='bar', figsize=(14, 8))\n",
    "# plt.title('Comparison of Actual and Predicted Responses')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.squeeze(y_test)\n",
    "y_pred = np.squeeze(y_pred)\n",
    "\n",
    "# Compare actual and predicted responses\n",
    "comparison_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "\n",
    "# Sample some data to plot\n",
    "sampled_data = comparison_df.sample(50, random_state=42)\n",
    "sampled_data.plot(kind='bar', figsize=(14, 8))\n",
    "plt.title('Comparison of Actual and Predicted Responses')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from matplotlib import pyplot\n",
    "from numpy import where\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,\n",
    " n_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=1)\n",
    "# summarize class distribution\n",
    "counter = Counter(y)\n",
    "print(counter)\n",
    "# scatter plot of examples by class label\n",
    "for label, _ in counter.items():\n",
    " row_ix = where(y == label)[0]\n",
    " pyplot.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label))\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Scatter plot for random forest\n",
    "# \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "features = X_train.columns\n",
    "importances = model.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
