{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install and setup kaggle and api key\n",
    "get a kaggle account\n",
    "Get Kaggle API\n",
    "conda install kaggle\n",
    "copy the kaggle.json file from download to your user directory/.kaggle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data using an API call\n",
    "kaggle.api.dataset_download_files('rodsaldanha/arketing-campaign', path='resources', unzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "data = pd.read_csv(\"./resources/marketing_campaign.csv\",delimiter=';')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA (Exploratory Data Analysis)\n",
    "We will revisit this. For now We want the rough draft of the model\n",
    "#\n",
    "During EDA\n",
    "\n",
    "Visualize the data using plots and graphs to understand distributions and relationships between variables.\n",
    "Calculate summary statistics to get a sense of the central tendencies and variability.\n",
    "Identify any correlations between variables that might influence model choices.\n",
    "Detect and treat missing values or outliers that could skew the results of your analysis.\n",
    "Explore the data's structure to inform feature selection and engineering, which are key to building effective machine learning models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display (data.head())\n",
    "# what does our data look like? At this point also use any documentation on the data set to find out what each value means and how it might be used is solving the business problem\n",
    "print (f'Columns with NA valuses \\n {data.isna().sum()[lambda x: x > 0]}')\n",
    "# Make desision about null values. Can we fill them of should we drop rows with null values?\n",
    "non_numeric= (data.dtypes[(data.dtypes != 'int64') & (data.dtypes != 'float64')]).index.tolist()\n",
    "print (f'Columns that are not numeric :\\n {non_numeric}')\n",
    "# Explore non numberic type to see how we can use them in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just to get started we will drop NA and columns that are not numberic. this will let us get a rough model\n",
    "# we come back to this and preprocess based on the draft results if needed\n",
    "\n",
    "\n",
    "data_drop_columns = data.drop(columns=non_numeric, axis=1)\n",
    "data_drop_na = data_drop_columns.dropna()\n",
    "df = data_drop_na.copy()\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into Train and Test\n",
    "X = df.drop('Response', axis=1)\n",
    "y = df[\"Response\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)\n",
    "# This will split 'X' and 'y' such that 80% is used for training and 20% is used for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what does a logistic model score look like without scaling?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling the data evens out the high and low values so on one column dominates over all others\n",
    "We will want to compare the scores of standard scalar to Min Max scalar to pick the bast scaling methood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the X data by using StandardScaler()\n",
    "scaler_ss = StandardScaler().fit(X_train)\n",
    "X_train_ss_scaled = scaler_ss.transform(X_train)\n",
    "X_train_ss_scaled\n",
    "\n",
    "# Transform the test dataset based on the fit from the training dataset\n",
    "X_test_ss_scaled = scaler_ss.transform(X_test)\n",
    "X_test_ss_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets look at min max scaler\n",
    "scaler_mm = MinMaxScaler().fit(X_train)\n",
    "X_train_mm_scaled = scaler_mm.transform(X_train)\n",
    "display (X_train_mm_scaled)\n",
    "\n",
    "X_test_mm_scaled = scaler_mm.transform(X_test)\n",
    "display (X_test_mm_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a `LogisticRegression` function and assign it \n",
    "# to a variable named `logistic_regression_model`.\n",
    "#\n",
    "logistic_regression_model_ss = LogisticRegression()\n",
    "# Fit the model\n",
    "logistic_regression_model_ss.fit(X_train_ss_scaled, y_train)\n",
    "\n",
    "logistic_regression_model_mm = LogisticRegression()\n",
    "\n",
    "logistic_regression_model_mm.fit(X_train_mm_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score the model\n",
    "\n",
    "print(f\"Standard Scaler\\nTraining Data Score: {logistic_regression_model_ss.score(X_train_ss_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {logistic_regression_model_ss.score(X_test_ss_scaled, y_test)}\")\n",
    "print(f\"Min Max Scaler\\nTraining Data Score: {logistic_regression_model_mm.score(X_train_mm_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {logistic_regression_model_mm.score(X_test_mm_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Romario models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **RANDOM FOREST MODEL\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create and train the model\n",
    "random_forest_model = RandomForestClassifier(random_state=42)\n",
    "random_forest_model.fit(X_train_ss_scaled, y_train)\n",
    "\n",
    "# Score the model\n",
    "print(f\"Random Forest - Training Data Score: {random_forest_model.score(X_train_ss_scaled, y_train)}\")\n",
    "print(f\"Random Forest - Testing Data Score: {random_forest_model.score(X_test_ss_scaled, y_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *******RANDOM FOREST WITH METRICS*********\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = random_forest_model.predict(X_test_ss_scaled)\n",
    "\n",
    "# Calculate precision, recall, F1 score\n",
    "print(f\"Random Forest - Precision: {precision_score(y_test, y_pred)}\")\n",
    "print(f\"Random Forest - Recall: {recall_score(y_test, y_pred)}\")\n",
    "print(f\"Random Forest - F1 Score: {f1_score(y_test, y_pred)}\")\n",
    "\n",
    "# Cross-validation scores\n",
    "cv_scores = cross_val_score(random_forest_model, X_train_ss_scaled, y_train, cv=5, scoring='accuracy')\n",
    "print(f\"Random Forest - Cross-Validation Accuracy: {cv_scores.mean()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ******* GradientBoostingClassifier MODELING\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Create and train the model\n",
    "gbm_model = GradientBoostingClassifier(random_state=42)\n",
    "gbm_model.fit(X_train_ss_scaled, y_train)\n",
    "\n",
    "# Score the model\n",
    "print(f\"Gradient Boosting Machine - Training Data Score: {gbm_model.score(X_train_ss_scaled, y_train)}\")\n",
    "print(f\"Gradient Boosting Machine - Testing Data Score: {gbm_model.score(X_test_ss_scaled, y_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ******* GradientBoostingClassifier MODELING WITH METRICS\n",
    "\n",
    "# Create and train the model\n",
    "gbm_model = GradientBoostingClassifier(random_state=1)\n",
    "gbm_model.fit(X_train_ss_scaled, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = gbm_model.predict(X_test_ss_scaled)\n",
    "\n",
    "# Calculate precision, recall, F1 score\n",
    "print(f\"Gradient Boosting Machine - Precision: {precision_score(y_test, y_pred)}\")\n",
    "print(f\"Gradient Boosting Machine - Recall: {recall_score(y_test, y_pred)}\")\n",
    "print(f\"Gradient Boosting Machine - F1 Score: {f1_score(y_test, y_pred)}\")\n",
    "\n",
    "# Cross-validation scores\n",
    "cv_scores = cross_val_score(gbm_model, X_train_ss_scaled, y_train, cv=5, scoring='accuracy')\n",
    "print(f\"Gradient Boosting Machine - Cross-Validation Accuracy: {cv_scores.mean()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create and train the model\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(X_train_ss_scaled, y_train)\n",
    "\n",
    "# Score the model\n",
    "print(f\"K-Nearest Neighbors - Training Data Score: {knn_model.score(X_train_ss_scaled, y_train)}\")\n",
    "print(f\"K-Nearest Neighbors - Testing Data Score: {knn_model.score(X_test_ss_scaled, y_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create and train the model\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(X_train_ss_scaled, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = knn_model.predict(X_test_ss_scaled)\n",
    "\n",
    "# Calculate precision, recall, F1 score\n",
    "print(f\"K-Nearest Neighbors - Precision: {precision_score(y_test, y_pred)}\")\n",
    "print(f\"K-Nearest Neighbors - Recall: {recall_score(y_test, y_pred)}\")\n",
    "print(f\"K-Nearest Neighbors - F1 Score: {f1_score(y_test, y_pred)}\")\n",
    "\n",
    "# Cross-validation scores\n",
    "cv_scores = cross_val_score(knn_model, X_train_ss_scaled, y_train, cv=5, scoring='accuracy')\n",
    "print(f\"K-Nearest Neighbors - Cross-Validation Accuracy: {cv_scores.mean()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Create and train the model\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train_ss_scaled, y_train)\n",
    "\n",
    "# Score the model\n",
    "print(f\"Support Vector Machine - Training Data Score: {svm_model.score(X_train_ss_scaled, y_train)}\")\n",
    "print(f\"Support Vector Machine - Testing Data Score: {svm_model.score(X_test_ss_scaled, y_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Create and train the model\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train_ss_scaled, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = svm_model.predict(X_test_ss_scaled)\n",
    "\n",
    "# Calculate precision, recall, F1 score\n",
    "print(f\"Support Vector Machine - Precision: {precision_score(y_test, y_pred)}\")\n",
    "print(f\"Support Vector Machine - Recall: {recall_score(y_test, y_pred)}\")\n",
    "print(f\"Support Vector Machine - F1 Score: {f1_score(y_test, y_pred)}\")\n",
    "\n",
    "# Cross-validation scores\n",
    "cv_scores = cross_val_score(svm_model, X_train_ss_scaled, y_train, cv=5, scoring='accuracy')\n",
    "print(f\"Support Vector Machine - Cross-Validation Accuracy: {cv_scores.mean()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create and train the model\n",
    "logistic_regression_model = LogisticRegression()\n",
    "logistic_regression_model.fit(X_train_ss_scaled, y_train)\n",
    "\n",
    "# Score the model\n",
    "print(f\"Logistic Regression - Training Data Score: {logistic_regression_model.score(X_train_ss_scaled, y_train)}\")\n",
    "print(f\"Logistic Regression - Testing Data Score: {logistic_regression_model.score(X_test_ss_scaled, y_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create and train the model\n",
    "logistic_regression_model = LogisticRegression()\n",
    "logistic_regression_model.fit(X_train_ss_scaled, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = logistic_regression_model.predict(X_test_ss_scaled)\n",
    "\n",
    "# Calculate precision, recall, F1 score\n",
    "print(f\"Logistic Regression - Precision: {precision_score(y_test, y_pred)}\")\n",
    "print(f\"Logistic Regression - Recall: {recall_score(y_test, y_pred)}\")\n",
    "print(f\"Logistic Regression - F1 Score: {f1_score(y_test, y_pred)}\")\n",
    "\n",
    "# Cross-validation scores\n",
    "cv_scores = cross_val_score(logistic_regression_model, X_train_ss_scaled, y_train, cv=5, scoring='accuracy')\n",
    "print(f\"Logistic Regression - Cross-Validation Accuracy: {cv_scores.mean()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create and train the model\n",
    "decision_tree_model = DecisionTreeClassifier(random_state=1)\n",
    "decision_tree_model.fit(X_train_ss_scaled, y_train)\n",
    "\n",
    "# Score the model\n",
    "print(f\"Decision Tree - Training Data Score: {decision_tree_model.score(X_train_ss_scaled, y_train)}\")\n",
    "print(f\"Decision Tree - Testing Data Score: {decision_tree_model.score(X_test_ss_scaled, y_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create and train the model\n",
    "decision_tree_model = DecisionTreeClassifier(random_state=1)\n",
    "decision_tree_model.fit(X_train_ss_scaled, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = decision_tree_model.predict(X_test_ss_scaled)\n",
    "\n",
    "# Calculate precision, recall, F1 score\n",
    "print(f\"Decision Tree - Precision: {precision_score(y_test, y_pred)}\")\n",
    "print(f\"Decision Tree - Recall: {recall_score(y_test, y_pred)}\")\n",
    "print(f\"Decision Tree - F1 Score: {f1_score(y_test, y_pred)}\")\n",
    "\n",
    "# Cross-validation scores\n",
    "cv_scores = cross_val_score(decision_tree_model, X_train_ss_scaled, y_train, cv=5, scoring='accuracy')\n",
    "print(f\"Decision Tree - Cross-Validation Accuracy: {cv_scores.mean()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
