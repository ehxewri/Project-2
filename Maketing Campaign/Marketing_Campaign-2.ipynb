{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install and Set Up Kaggle and API Key\n",
    "\n",
    "Follow these steps to install and configure the Kaggle API on your system:\n",
    "\n",
    "1. **Create a Kaggle Account**\n",
    "   - Visit [Kaggle](https://www.kaggle.com) and sign up for an account.\n",
    "\n",
    "2. **Obtain Kaggle API Key**\n",
    "   - Go to your Kaggle account settings.\n",
    "   - Find the \"API\" section and click on \"Create New API Token\".\n",
    "   - This will download a `kaggle.json` file containing your API key.\n",
    "\n",
    "3. **Install Kaggle Package**\n",
    "   - Use Conda to install the Kaggle package by running:\n",
    "     ```bash\n",
    "     conda install kaggle\n",
    "     ```\n",
    "\n",
    "4. **Configure API Key**\n",
    "   - Copy the `kaggle.json` file to your user directory under the `.kaggle` folder. On most systems, you can use the following command:\n",
    "     ```bash\n",
    "     mkdir -p ~/.kaggle\n",
    "     cp path_to_downloaded_kaggle.json ~/.kaggle/kaggle.json\n",
    "     chmod 600 ~/.kaggle/kaggle.json\n",
    "     ```\n",
    "   - Ensure the `.kaggle` directory and the `kaggle.json` file have the proper permissions by setting:\n",
    "     ```bash\n",
    "     chmod 600 ~/.kaggle/kaggle.json\n",
    "     ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import kaggle\n",
    "import Marketing_Campaign as mc\n",
    "# Pre processing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, OrdinalEncoder\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Scoring \n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# models \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#potting\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/rodsaldanha/arketing-campaign\n"
     ]
    }
   ],
   "source": [
    "# Get the data using an API call\n",
    "kaggle.api.dataset_download_files('rodsaldanha/arketing-campaign', path='resources', unzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "data = pd.read_csv(\"./resources/marketing_campaign.csv\",delimiter=';')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA (Exploratory Data Analysis)\n",
    "We will revisit this. For now We want the rough draft of the model\n",
    "#\n",
    "During EDA\n",
    "\n",
    "Visualize the data using plots and graphs to understand distributions and relationships between variables.\n",
    "Calculate summary statistics to get a sense of the central tendencies and variability.\n",
    "Identify any correlations between variables that might influence model choices.\n",
    "Detect and treat missing values or outliers that could skew the results of your analysis.\n",
    "Explore the data's structure to inform feature selection and engineering, which are key to building effective machine learning models.\n",
    "\n",
    "# read any and all documentation you can find on your dataset to understand it better\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Year_Birth</th>\n",
       "      <th>Education</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Income</th>\n",
       "      <th>Kidhome</th>\n",
       "      <th>Teenhome</th>\n",
       "      <th>Dt_Customer</th>\n",
       "      <th>Recency</th>\n",
       "      <th>MntWines</th>\n",
       "      <th>...</th>\n",
       "      <th>NumWebVisitsMonth</th>\n",
       "      <th>AcceptedCmp3</th>\n",
       "      <th>AcceptedCmp4</th>\n",
       "      <th>AcceptedCmp5</th>\n",
       "      <th>AcceptedCmp1</th>\n",
       "      <th>AcceptedCmp2</th>\n",
       "      <th>Complain</th>\n",
       "      <th>Z_CostContact</th>\n",
       "      <th>Z_Revenue</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5524</td>\n",
       "      <td>1957</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Single</td>\n",
       "      <td>58138.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-09-04</td>\n",
       "      <td>58</td>\n",
       "      <td>635</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2174</td>\n",
       "      <td>1954</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Single</td>\n",
       "      <td>46344.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-03-08</td>\n",
       "      <td>38</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4141</td>\n",
       "      <td>1965</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Together</td>\n",
       "      <td>71613.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-08-21</td>\n",
       "      <td>26</td>\n",
       "      <td>426</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6182</td>\n",
       "      <td>1984</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Together</td>\n",
       "      <td>26646.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-02-10</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5324</td>\n",
       "      <td>1981</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Married</td>\n",
       "      <td>58293.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-01-19</td>\n",
       "      <td>94</td>\n",
       "      <td>173</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID  Year_Birth   Education Marital_Status   Income  Kidhome  Teenhome  \\\n",
       "0  5524        1957  Graduation         Single  58138.0        0         0   \n",
       "1  2174        1954  Graduation         Single  46344.0        1         1   \n",
       "2  4141        1965  Graduation       Together  71613.0        0         0   \n",
       "3  6182        1984  Graduation       Together  26646.0        1         0   \n",
       "4  5324        1981         PhD        Married  58293.0        1         0   \n",
       "\n",
       "  Dt_Customer  Recency  MntWines  ...  NumWebVisitsMonth  AcceptedCmp3  \\\n",
       "0  2012-09-04       58       635  ...                  7             0   \n",
       "1  2014-03-08       38        11  ...                  5             0   \n",
       "2  2013-08-21       26       426  ...                  4             0   \n",
       "3  2014-02-10       26        11  ...                  6             0   \n",
       "4  2014-01-19       94       173  ...                  5             0   \n",
       "\n",
       "   AcceptedCmp4  AcceptedCmp5  AcceptedCmp1  AcceptedCmp2  Complain  \\\n",
       "0             0             0             0             0         0   \n",
       "1             0             0             0             0         0   \n",
       "2             0             0             0             0         0   \n",
       "3             0             0             0             0         0   \n",
       "4             0             0             0             0         0   \n",
       "\n",
       "   Z_CostContact  Z_Revenue  Response  \n",
       "0              3         11         1  \n",
       "1              3         11         0  \n",
       "2              3         11         0  \n",
       "3              3         11         0  \n",
       "4              3         11         0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2240, 29)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "display (data.head())\n",
    "# what does our data look like? At this point also use any documentation on the data set to find out what each value means and how it might be used is solving the business problem\n",
    "print (f'{data.shape}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop Percent of the rows is %2\n",
      "If the number of NA values in a column is less than the calculated threshold, automatically drop the NA rows.\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "# Preprocess = Clean up NA if number of NA in column is less that a percentage of rows\n",
    "# this automatically cleans up rows below a threshold and list columns when NA rows exceed the threshold\n",
    "data=mc.auto_drop_na(data,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns that are not numeric :\n",
      " ['Education', 'Marital_Status', 'Dt_Customer']\n",
      "\n",
      "Education\n",
      "Graduation    1116\n",
      "PhD            481\n",
      "Master         365\n",
      "2n Cycle       200\n",
      "Basic           54\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Marital_Status\n",
      "Married     857\n",
      "Together    573\n",
      "Single      471\n",
      "Divorced    232\n",
      "Widow        76\n",
      "Alone         3\n",
      "Absurd        2\n",
      "YOLO          2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Dt_Customer\n",
      "2012-08-31    12\n",
      "2012-09-12    11\n",
      "2013-02-14    11\n",
      "2014-05-12    11\n",
      "2013-08-20    10\n",
      "              ..\n",
      "2012-08-05     1\n",
      "2012-11-18     1\n",
      "2014-05-09     1\n",
      "2013-06-26     1\n",
      "2014-01-09     1\n",
      "Name: count, Length: 662, dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Identify non numeric columns we will need to deal with\n",
    "non_numeric= (data.dtypes[(data.dtypes != 'int64') & (data.dtypes != 'float64')]).index.tolist()\n",
    "# display (data.dtypes)\n",
    "print (f'Columns that are not numeric :\\n {non_numeric}\\n')\n",
    "\n",
    "for column in non_numeric:\n",
    "    print (data[column].value_counts())\n",
    "    print ('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# non numeric column \n",
    "\n",
    "- Education OrdinalEncoder because education counts\n",
    "     - 0 - **Basic** This generally refers to elementary or primary education.\n",
    "     - 1 - **2n Cycle** This is not a commonly used term globally but might refer to secondary education or an intermediary level in some education systems.\n",
    "     - 2 - **Graduation** Typically refers to the completion of a bachelor's or undergraduate degree.\n",
    "     - 3 - **Master** A postgraduate degree that follows the completion of a bachelor's degree.\n",
    "     - 4 - **PhD** The highest university degree, typically following a master's degree.\n",
    "- Marital_Status - The status has no weighted values. change none standard answers to single and then one hot encode three remaining values\n",
    "     - Alone     Single\n",
    "     - Absurd    Single\n",
    "     - YOLO      Single\n",
    "\n",
    "- Dt_Customer - We will convert to data time and represent this in number of months the cusomter has been with us\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ID  Year_Birth Marital_Status   Income  Kidhome  Teenhome Dt_Customer  \\\n",
      "0  5524.0      1957.0         Single  58138.0      0.0       0.0  2012-09-04   \n",
      "1  2174.0      1954.0         Single  46344.0      1.0       1.0  2014-03-08   \n",
      "2  4141.0      1965.0       Together  71613.0      0.0       0.0  2013-08-21   \n",
      "3  6182.0      1984.0       Together  26646.0      1.0       0.0  2014-02-10   \n",
      "4  5324.0      1981.0        Married  58293.0      1.0       0.0  2014-01-19   \n",
      "\n",
      "   Recency  MntWines  MntFruits  ...  AcceptedCmp3  AcceptedCmp4  \\\n",
      "0     58.0     635.0       88.0  ...           0.0           0.0   \n",
      "1     38.0      11.0        1.0  ...           0.0           0.0   \n",
      "2     26.0     426.0       49.0  ...           0.0           0.0   \n",
      "3     26.0      11.0        4.0  ...           0.0           0.0   \n",
      "4     94.0     173.0       43.0  ...           0.0           0.0   \n",
      "\n",
      "   AcceptedCmp5  AcceptedCmp1  AcceptedCmp2  Complain  Z_CostContact  \\\n",
      "0           0.0           0.0           0.0       0.0            3.0   \n",
      "1           0.0           0.0           0.0       0.0            3.0   \n",
      "2           0.0           0.0           0.0       0.0            3.0   \n",
      "3           0.0           0.0           0.0       0.0            3.0   \n",
      "4           0.0           0.0           0.0       0.0            3.0   \n",
      "\n",
      "   Z_Revenue  Response  Education  \n",
      "0       11.0       1.0        2.0  \n",
      "1       11.0       0.0        2.0  \n",
      "2       11.0       0.0        2.0  \n",
      "3       11.0       0.0        2.0  \n",
      "4       11.0       0.0        4.0  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "# Education encode\n",
    "categories = ['Basic','2n Cycle','Graduation','Master','PhD']\n",
    "column = 'Education'\n",
    "data1 = mc.preprocess_ord(data,column,categories)\n",
    "data1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the generational labels and ranges\n",
    "def assign_generation(year):\n",
    "    if year <= 1927:\n",
    "        return 'Greatest Generation'\n",
    "    elif 1928 <= year <= 1945:\n",
    "        return 'Silent Generation'\n",
    "    elif 1946 <= year <= 1964:\n",
    "        return 'Baby Boomers'\n",
    "    elif 1965 <= year <= 1980:\n",
    "        return 'Generation X'\n",
    "    elif 1981 <= year <= 1996:\n",
    "        return 'Millennials (Gen Y)'\n",
    "    elif 1997 <= year <= 2012:\n",
    "        return 'Generation Z (Gen Z)'\n",
    "    else:\n",
    "        return 'Generation Alpha'\n",
    "\n",
    "# Apply the function to create a new column 'Generation'\n",
    "data['Generation'] = data['Year_Birth'].apply(assign_generation)\n",
    "\n",
    "# Print out a sample to ensure correctness\n",
    "print(data['Generation'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = data['Dt_Customer'].min()\n",
    "end_date = data['Dt_Customer'].max()\n",
    "\n",
    "# Display the start and end dates\n",
    "print(f\"Start Date: {start_date}\")\n",
    "print(f\"End Date: {end_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "data['Dt_Customer'] = pd.to_datetime(data['Dt_Customer'])\n",
    "# set sample date to the date of the dataset creation\n",
    "sample_date = dt(2014, 6, 29)\n",
    "data['Months_Customer'] = ((sample_date.year - data['Dt_Customer'].dt.year) * 12 +\n",
    "                                 (sample_date.month - data['Dt_Customer'].dt.month))\n",
    "data = data.drop('Dt_Customer', axis=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just to get started we will drop NA and columns that are not numberic. this will let us get a rough model\n",
    "# we come back to this and preprocess based on the draft results if needed\n",
    "\n",
    "# data_drop_columns = data.drop(columns=non_numeric, axis=1)\n",
    "data_drop_columns = data.drop(columns=[\"ID\",\"Year_Birth\"], axis=1)\n",
    "data_drop_na = data_drop_columns.dropna()\n",
    "df = data_drop_na.copy()\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look for balance of our data\n",
    "df[\"Response\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into Train and Test **80/20 split**\n",
    "# add verbage as to why we picked response\n",
    "\n",
    "# X = df.drop('Response', axis=1)\n",
    "# y = df[\"Response\"]\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "# # This will split 'X' and 'y' such that 80% is used for training and 20% is used for testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Education\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[['Year_Birth', 'Generation']].head(10))\n",
    "data[\"Generation\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the training data\n",
    "df_proc=X_preprocess(df)\n",
    "display (df_proc)\n",
    "# df\n",
    "display (df_proc['Education'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_proc.drop(columns='Response')\n",
    "y = df_proc['Response'].values.reshape(-1,1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proc[\"Response\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# this section will address the data imbalance we see in our y value. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Applying RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "# Check the new class distribution\n",
    "print(y_resampled.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Applying RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_resampled, y_resampled = rus.fit_resample(X, y)\n",
    "\n",
    "# Check the new class distribution\n",
    "print(y_resampled.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Applying SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Check the new class distribution\n",
    "print(y_resampled.value_counts())\n",
    "# Split the resampled data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.20, random_state=42)\n",
    "\n",
    "# Train a RandomForestClassifier with class weights\n",
    "rfc = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = rfc.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "# Applying SMOTEENN (combination of SMOTE and Edited Nearest Neighbors)\n",
    "smote_enn = SMOTEENN(random_state=42)\n",
    "X_resampled, y_resampled = smote_enn.fit_resample(X, y)\n",
    "\n",
    "# Split the resampled data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.20, random_state=42)\n",
    "\n",
    "# Train and evaluate the model\n",
    "rfc = RandomForestClassifier(random_state=42)\n",
    "rfc.fit(X_train, y_train)\n",
    "y_pred = rfc.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the X data by using StandardScaler()\n",
    "scaler_ss = StandardScaler().fit(X_train)\n",
    "X_train_ss_scaled = scaler_ss.transform(X_train)\n",
    "display (X_train_ss_scaled)\n",
    "\n",
    "# Transform the test dataset based on the fit from the training dataset\n",
    "X_test_ss_scaled = scaler_ss.transform(X_test)\n",
    "display (X_test_ss_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets look at min max scaler\n",
    "scaler_mm = MinMaxScaler().fit(X_train)\n",
    "X_train_mm_scaled = scaler_mm.transform(X_train)\n",
    "display (X_train_mm_scaled)\n",
    "#\n",
    "X_test_mm_scaled = scaler_mm.transform(X_test)\n",
    "display (X_test_mm_scaled)\n",
    "\n",
    "X_test_mm_scaled = scaler_mm.transform(X_test)\n",
    "display (X_test_mm_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Logistic model to find out what scaler works best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a `LogisticRegression` function and assign it \n",
    "# to a variable named `logistic_regression_model`.\n",
    "logistic_regression_model_ss = LogisticRegression()\n",
    "logistic_regression_model_ss.fit(X_train_ss_scaled, y_train)\n",
    "#\n",
    "logistic_regression_model_mm = LogisticRegression()\n",
    "logistic_regression_model_mm.fit(X_train_mm_scaled, y_train)\n",
    "# Score the Logistic model\n",
    "\n",
    "print(f\"Standard Scaler\\nTraining Data Score: {logistic_regression_model_ss.score(X_train_ss_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {logistic_regression_model_ss.score(X_test_ss_scaled, y_test)}\")\n",
    "print(f\"Min Max Scaler\\nTraining Data Score: {logistic_regression_model_mm.score(X_train_mm_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {logistic_regression_model_mm.score(X_test_mm_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test models\n",
    "    -RANDOM FOREST MODEL\n",
    "    -Decision Tree Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **RANDOM FOREST MODEL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the model\n",
    "random_forest_model = RandomForestClassifier(random_state=42)\n",
    "random_forest_model.fit(X_train_ss_scaled, y_train)\n",
    "# Predict on test set\n",
    "y_pred = random_forest_model.predict(X_test_ss_scaled)\n",
    "# Calculate precision, recall, F1 score\n",
    "# Cross-validation scores\n",
    "cv_scores = cross_val_score(random_forest_model, X_train_ss_scaled, y_train, cv=5, scoring='accuracy')\n",
    "display (random_forest_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the model\n",
    "decision_tree_model = DecisionTreeClassifier(random_state=42)\n",
    "decision_tree_model.fit(X_train_ss_scaled, y_train)\n",
    "# Predict on test set\n",
    "y_pred = decision_tree_model.predict(X_test_ss_scaled)\n",
    "# Cross-validation scores\n",
    "cv_scores = cross_val_score(decision_tree_model, X_train_ss_scaled, y_train, cv=5, scoring='accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test models\n",
    "# -RANDOM FOREST MODEL\n",
    "# Score the model\n",
    "print(f\"Random Forest - Training Data Score: {random_forest_model.score(X_train_ss_scaled, y_train)}\")\n",
    "print(f\"Random Forest - Testing Data Score: {random_forest_model.score(X_test_ss_scaled, y_test)}\")\n",
    "print(f\"Random Forest - Precision: {precision_score(y_test, y_pred)}\")\n",
    "print(f\"Random Forest - Recall: {recall_score(y_test, y_pred)}\")\n",
    "print(f\"Random Forest - F1 Score: {f1_score(y_test, y_pred)}\")\n",
    "print(f\"Random Forest - Cross-Validation Accuracy: {cv_scores.mean()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.squeeze(y_test)\n",
    "y_pred = np.squeeze(y_pred)\n",
    "\n",
    "# Compare actual and predicted responses\n",
    "comparison_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "\n",
    "# Sample some data to plot\n",
    "sampled_data = comparison_df.sample(50, random_state=42)\n",
    "sampled_data.plot(kind='bar', figsize=(14, 8))\n",
    "plt.title('Comparison of Actual and Predicted Responses')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Scatter plot for random forest\n",
    "# \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "features = X_train.columns\n",
    "importances = model.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
